{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30e98ff-daf1-4466-8ca0-0501b0fb324d",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac74d25a-390a-4bfe-a8e8-68b3d724037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bcchapi\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import re\n",
    "import xlrd\n",
    "import openpyxl\n",
    "import os\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337c7ac",
   "metadata": {},
   "source": [
    "### API BDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fc64a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "siete = bcchapi.Siete(\"pbustamante@vectorcapital.cl\", \"Vector.2025\")\n",
    "fecha_hoy = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "## EURO\n",
    "df_euro_obs = siete.cuadro(\n",
    "series=[\"F072.CLP.EUR.N.O.D\"],\n",
    "nombres = [\"euro\"],\n",
    "desde=\"2025-01-01\",\n",
    "hasta=fecha_hoy)\n",
    "\n",
    "df_euro_obs = df_euro_obs.reset_index()\n",
    "df_euro_obs.columns = ['Fecha', 'Euro TC']\n",
    "df_euro_obs[\"Fecha\"] = pd.to_datetime(df_euro_obs[\"Fecha\"]).dt.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "### USD\n",
    "df_dolar_obs = siete.cuadro(\n",
    "series=[\"F073.TCO.PRE.Z.D\"],\n",
    "nombres = [\"dolar\"],\n",
    "desde=\"2025-01-01\",\n",
    "hasta=fecha_hoy)\n",
    "df_dolar_obs = df_dolar_obs.reset_index()\n",
    "df_dolar_obs.columns = ['Fecha', 'Dolar TC']\n",
    "df_dolar_obs[\"Fecha\"] = pd.to_datetime(df_dolar_obs[\"Fecha\"]).dt.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae9be1",
   "metadata": {},
   "source": [
    "### FBICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e28278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_año_desde_encabezado_BICE(texto_columna):\n",
    "    \"\"\"Extrae el año desde el texto del encabezado (antes del símbolo '|')\"\"\"\n",
    "    before_pipe = re.split(r'\\|', texto_columna)[0].strip()\n",
    "    match = re.search(r'\\b(\\d{4})\\b', before_pipe)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "def cargar_cartola_bice(ruta_archivo, tipo_mon='clp', df_euro_obs=None):\n",
    "    df = pd.read_excel(ruta_archivo)\n",
    "    text = df.columns[0]\n",
    "    year = extraer_año_desde_encabezado_BICE(text)\n",
    "    \n",
    "    # CLEAN ENTRADA y SALIDA\n",
    "    df = df.iloc[9:]\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.iloc[2:].reset_index(drop=True)\n",
    "    first_empty_index = df[df.isnull().all(axis=1)].index.min() # SALIDA\n",
    "    if pd.notna(first_empty_index):\n",
    "        df = df.iloc[:first_empty_index]\n",
    "    # Fix fecha (completar y agregar año) y formatear dd-mm-yyyy; sacar col saldo contable\n",
    "    df[\"Fecha\"] = df[\"Fecha\"].replace(\"-\", pd.NA).ffill()\n",
    "    df[\"Fecha\"] = df[\"Fecha\"].astype(str).str.strip() + \"-\" + year\n",
    "    df[\"Fecha\"] = pd.to_datetime(df[\"Fecha\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "    df[\"Fecha\"] = df[\"Fecha\"].dt.strftime(\"%d-%m-%Y\")\n",
    "    if 'Saldo Contable' in df.columns:\n",
    "        del df['Saldo Contable']\n",
    "    # Si tipo_mon = 'eur', unir con tipo de cambio y convertir\n",
    "    if tipo_mon.lower() == 'eur':\n",
    "        if df_euro_obs is None:\n",
    "            raise ValueError(\"Debe proporcionar df_euro_obs cuando tipo_mon es 'eur'\")\n",
    "\n",
    "        df = pd.merge(df, df_euro_obs, how='left', on='Fecha')\n",
    "\n",
    "        # a numéricos y nuevos campos\n",
    "        df['Cargos'] = pd.to_numeric(df['Cargos'], errors='coerce')\n",
    "        df['Abonos'] = pd.to_numeric(df['Abonos'], errors='coerce')\n",
    "        df['Euro TC'] = pd.to_numeric(df['Euro TC'], errors='coerce')\n",
    "        df['Cargos Moneda de Origen'] = df['Cargos'] / df['Euro TC']\n",
    "        df['Abono Moneda de Origen'] = df['Abonos'] / df['Euro TC']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50902f8c",
   "metadata": {},
   "source": [
    "### CARTOLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d7acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_dir = r\"Y:\\Cartolas bancarias Contabilidad\\2025\\Mayo 2025\\BICE\\BICE 01-35659-3\"\n",
    "archivos = os.listdir(ruta_dir)\n",
    "archivos_xlsx = [f for f in archivos if f.lower().endswith('.xlsx') and os.path.isfile(os.path.join(ruta_dir, f))]\n",
    "\n",
    "dfs = []\n",
    "for archivo in archivos_xlsx:\n",
    "    ruta_archivo = os.path.join(ruta_dir, archivo)\n",
    "    df = cargar_cartola_bice(ruta_archivo, tipo_mon='clp')\n",
    "    dfs.append(df)\n",
    "\n",
    "cartola_clp_RACIONAL = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c84677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_rut = cartola_clp_RACIONAL\n",
    "\n",
    "# General\n",
    "def extraer_rut(texto, n=1):\n",
    "    \"\"\"\n",
    "    Extrae el n-ésimo RUT chileno del texto (por defecto el primero).\n",
    "    Si no encuentra, retorna None.\n",
    "    \"\"\"\n",
    "    # Busca todos los RUTs con 7 u 8 dígitos, guion y dígito/K\n",
    "    ruts = re.findall(r'(\\d{7,8}-[0-9Kk])', texto.replace('.', ''))\n",
    "    if len(ruts) >= n:\n",
    "        return ruts[n-1].upper()\n",
    "    return None\n",
    "\n",
    "# Ejemplo: para extraer el primer RUT\n",
    "df_to_rut['IDENTIFICADOR'] = df_to_rut['Descripción'].apply(lambda x: extraer_rut(str(x), n=1))\n",
    "\n",
    "# Extrae el RUT desde cualquier parte de la descripción\n",
    "df_to_rut['IDENTIFICADOR'] = df_to_rut['Descripción'].apply(lambda x: extraer_rut(str(x)))\n",
    "\n",
    "# Excepción\n",
    "cond_excepcional = df_to_rut['Descripción'].str.contains(r'^Transf\\. via Internet a cuenta .*desde VECTOR CAPITAL CORREDORES DE BOLSA SPA', regex=True)\n",
    "df_to_rut.loc[cond_excepcional, 'IDENTIFICADOR'] = '076513680-6'\n",
    "\n",
    "# Excepción\n",
    "cond_excepcional = df_to_rut['Descripción'].str.contains(r'^Transf\\. via Internet a cuenta .*desde VECTOR CAPITAL CORREDORES DE BOLSA SPA', regex=True)\n",
    "df_to_rut.loc[cond_excepcional, 'IDENTIFICADOR'] = '076513680-6'\n",
    "df_to_rut['IDENTIFICADOR'] = df_to_rut['IDENTIFICADOR'].str.replace('.', '', regex=False)\n",
    "\n",
    "## Extraer hora depósito para el match con dashboard RC\n",
    "def extraer_fecha_hora(texto):\n",
    "    match = re.search(r'(\\d{2}/\\d{2}/\\d{4})\\s*a\\s*las\\s*(\\d{2}:\\d{2})', str(texto))\n",
    "    if match:\n",
    "        return f\"{match.group(1)} {match.group(2)}\"\n",
    "    return None\n",
    "\n",
    "df_to_rut['Fecha_transferencia'] = df_to_rut['Descripción'].apply(extraer_fecha_hora)\n",
    "df_to_rut['Fecha_transferencia'] = pd.to_datetime(df_to_rut['Fecha_transferencia'], format='%d/%m/%Y %H:%M')\n",
    "df_to_rut['Fecha_transferencia'] = df_to_rut['Fecha_transferencia'].dt.strftime('%d-%m-%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560909da",
   "metadata": {},
   "source": [
    "Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608280c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>9</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Documento</th>\n",
       "      <th>Descripción</th>\n",
       "      <th>Cargos</th>\n",
       "      <th>Abonos</th>\n",
       "      <th>IDENTIFICADOR</th>\n",
       "      <th>Fecha_transferencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18273</th>\n",
       "      <td>19-05-2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transferencia de CLAUDIO ALBERTO CAMPOS HAN Ru...</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>19222315-6</td>\n",
       "      <td>19-05-2025 07:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "9           Fecha Documento  \\\n",
       "18273  19-05-2025       NaN   \n",
       "\n",
       "9                                            Descripción Cargos Abonos  \\\n",
       "18273  Transferencia de CLAUDIO ALBERTO CAMPOS HAN Ru...      0  35000   \n",
       "\n",
       "9     IDENTIFICADOR Fecha_transferencia  \n",
       "18273    19222315-6    19-05-2025 07:19  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_rut[df_to_rut['Descripción'] == 'Transferencia de CLAUDIO ALBERTO CAMPOS HAN Rut 19222315-6 desde Banco BICE a VECTOR CAPITAL CORREDORES DE BOLSA SPA Rut 76513680-6 a Cuenta Corriente de Banco BICE,el 19/05/2025 a las 07:19 hrs.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ef543",
   "metadata": {},
   "source": [
    "### QRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f6f77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco Betancour\\AppData\\Local\\Temp\\ipykernel_15732\\789851610.py:35: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_APORET_detalle = pd.read_sql(query_universal['query_APORET'], conn)\n"
     ]
    }
   ],
   "source": [
    "F_i  = '2025-04-29'\n",
    "F    = '2025-06-02' \n",
    "\n",
    "query_universal = {\n",
    "\n",
    "        'query_APORET': f\"\"\"\n",
    "        SELECT \n",
    "               CARGO_ABONO, \n",
    "               NUM_CUENTA, \n",
    "               IDENTIFICADOR,\n",
    "               NOMBRE_CLI, \n",
    "               COD_MOV, \n",
    "               DSC_MOV_CAJA, \n",
    "               FECHA_MOVIMIENTO,\n",
    "               FECHA_LIQUIDACION, \n",
    "               MONTO, \n",
    "               NOMBRE_ASESOR, \n",
    "               TIPO_CAJA,\n",
    "               MOV_AUTOMATICO,\n",
    "               OBS_MOV_CAJA\n",
    "\n",
    "        FROM [Capitaria].[dbo].[MOV_CAJA_CLI_JGG]\n",
    "        WHERE COD_MOV IN (\n",
    "            'APO_PAT',\n",
    "            'APO_PAT_AT',\n",
    "            'APO_PAT_BT',\n",
    "            'APO_PAT_LI',\n",
    "            'APO_PAT_RC'\n",
    "            )\n",
    "        AND FECHA_MOVIMIENTO BETWEEN CONVERT(datetime, '{F_i}', 120) AND CONVERT(datetime, '{F}', 120)\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "df_APORET_detalle = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8643a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILTRAR CARTOLA\n",
    "# Filtrar solo depósitos (Abonos > 0) y que IDENTIFICADOR no sea vacío ni nulo\n",
    "df_to_rut = df_to_rut[(df_to_rut['Abonos'] > 0) & (df_to_rut['IDENTIFICADOR'].notna()) & (df_to_rut['IDENTIFICADOR'].str.strip() != '')]\n",
    "\n",
    "# Asegura que las fechas sean datetime\n",
    "df_to_rut['Fecha'] = pd.to_datetime(df_to_rut['Fecha'], format='%d-%m-%Y', errors='coerce')\n",
    "df_APORET_detalle['FECHA_MOVIMIENTO'] = pd.to_datetime(df_APORET_detalle['FECHA_MOVIMIENTO'], errors='coerce')\n",
    "\n",
    "# Ordena ambos DataFrames por IDENTIFICADOR, MONTO/Abonos y fecha\n",
    "df_to_rut = df_to_rut.sort_values(['IDENTIFICADOR', 'Abonos', 'Fecha'])\n",
    "df_APORET_detalle = df_APORET_detalle.sort_values(['IDENTIFICADOR', 'MONTO', 'FECHA_MOVIMIENTO'])\n",
    "\n",
    "# Normaliza los montos a float y luego a int para evitar diferencias por decimales\n",
    "df_to_rut['Abonos'] = pd.to_numeric(df_to_rut['Abonos'], errors='coerce').fillna(0).astype(int)\n",
    "df_APORET_detalle['MONTO'] = pd.to_numeric(df_APORET_detalle['MONTO'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# ---- Rut k to K\n",
    "df_to_rut['IDENTIFICADOR'] = df_to_rut['IDENTIFICADOR'].str.upper()\n",
    "df_APORET_detalle['IDENTIFICADOR'] = df_APORET_detalle['IDENTIFICADOR'].str.upper()\n",
    "\n",
    "# Ahora crea la clave\n",
    "df_to_rut['clave'] = df_to_rut['IDENTIFICADOR'].astype(str) + '_' + df_to_rut['Abonos'].astype(str)\n",
    "df_APORET_detalle['clave'] = df_APORET_detalle['IDENTIFICADOR'].astype(str) + '_' + df_APORET_detalle['MONTO'].astype(str)\n",
    "\n",
    "# mod\n",
    "df_to_rut = df_to_rut.reset_index().rename(columns={'index': 'idx_cartola'})\n",
    "\n",
    "\n",
    "# Para cada fila de df_to_rut, busca el match más cercano en fecha en df_APORET_detalle\n",
    "resultados = []\n",
    "usados = set()\n",
    "\n",
    "for idx, row in df_to_rut.iterrows():\n",
    "    candidatos = df_APORET_detalle[df_APORET_detalle['clave'] == row['clave']]\n",
    "    if not candidatos.empty:\n",
    "        # Calcula la diferencia absoluta de días\n",
    "        candidatos = candidatos.assign(diff_days=(candidatos['FECHA_MOVIMIENTO'] - row['Fecha']).abs())\n",
    "        # Elige el más cercano que no haya sido usado\n",
    "        candidatos = candidatos[~candidatos.index.isin(usados)]\n",
    "        if not candidatos.empty:\n",
    "            elegido = candidatos.loc[candidatos['diff_days'].idxmin()]\n",
    "            usados.add(elegido.name)\n",
    "            merged_row = {**row, **elegido}\n",
    "            resultados.append(merged_row)\n",
    "        else:\n",
    "            # No hay candidatos disponibles (ya usados)\n",
    "            merged_row = {**row}\n",
    "            for col in df_APORET_detalle.columns:\n",
    "                if col not in merged_row:\n",
    "                    merged_row[col] = np.nan\n",
    "            resultados.append(merged_row)\n",
    "    else:\n",
    "        # No hay candidatos\n",
    "        merged_row = {**row}\n",
    "        for col in df_APORET_detalle.columns:\n",
    "            if col not in merged_row:\n",
    "                merged_row[col] = np.nan\n",
    "        resultados.append(merged_row)\n",
    "\n",
    "df_match = pd.DataFrame(resultados)\n",
    "\n",
    "# ---- Solo dejar movimientos realmente matcheados (ambos lados tienen datos)\n",
    "df_match = df_match[df_match['MONTO'].notna()]\n",
    "# No match en cartola: los que no lograron match en GPI\n",
    "no_match_cartola = df_to_rut[~df_to_rut['idx_cartola'].isin(df_match['idx_cartola'])]\n",
    "\n",
    "# No match en APORET (los que no fueron usados)\n",
    "no_match_aporet = df_APORET_detalle[~df_APORET_detalle.index.isin(usados)]\n",
    "\n",
    "# Exporta a Excel\n",
    "with pd.ExcelWriter('Temporal/ViernesCartolaGPI_realmatch3.xlsx') as writer:\n",
    "    df_match.to_excel(writer, sheet_name='Match', index=False)\n",
    "    df_to_rut.to_excel(writer, sheet_name='Cartola', index=False)\n",
    "    df_APORET_detalle.to_excel(writer, sheet_name='GPI', index=False)\n",
    "    no_match_cartola.to_excel(writer, sheet_name='No_Match_CARTOLA', index=False)\n",
    "    no_match_aporet.to_excel(writer, sheet_name='No_Match_APORET', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b718892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31158, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9aff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>9</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Documento</th>\n",
       "      <th>Descripción</th>\n",
       "      <th>Cargos</th>\n",
       "      <th>Abonos</th>\n",
       "      <th>IDENTIFICADOR</th>\n",
       "      <th>Fecha_transferencia</th>\n",
       "      <th>clave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>22706411</td>\n",
       "      <td>Abono por transferencia de Hernan Raul Contrer...</td>\n",
       "      <td>0</td>\n",
       "      <td>2000000</td>\n",
       "      <td>8234253-7</td>\n",
       "      <td>10-05-2025 09:01</td>\n",
       "      <td>8234253-7_2000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "9          Fecha Documento                                        Descripción  \\\n",
       "13248 2025-05-12  22706411  Abono por transferencia de Hernan Raul Contrer...   \n",
       "\n",
       "9     Cargos   Abonos IDENTIFICADOR Fecha_transferencia              clave  \n",
       "13248      0  2000000     8234253-7    10-05-2025 09:01  8234253-7_2000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CARGO_ABONO</th>\n",
       "      <th>NUM_CUENTA</th>\n",
       "      <th>IDENTIFICADOR</th>\n",
       "      <th>NOMBRE_CLI</th>\n",
       "      <th>COD_MOV</th>\n",
       "      <th>DSC_MOV_CAJA</th>\n",
       "      <th>FECHA_MOVIMIENTO</th>\n",
       "      <th>FECHA_LIQUIDACION</th>\n",
       "      <th>MONTO</th>\n",
       "      <th>NOMBRE_ASESOR</th>\n",
       "      <th>TIPO_CAJA</th>\n",
       "      <th>MOV_AUTOMATICO</th>\n",
       "      <th>OBS_MOV_CAJA</th>\n",
       "      <th>clave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CARGO_ABONO, NUM_CUENTA, IDENTIFICADOR, NOMBRE_CLI, COD_MOV, DSC_MOV_CAJA, FECHA_MOVIMIENTO, FECHA_LIQUIDACION, MONTO, NOMBRE_ASESOR, TIPO_CAJA, MOV_AUTOMATICO, OBS_MOV_CAJA, clave]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aidi =  '8234253-7'\n",
    "display(df_to_rut[df_to_rut['IDENTIFICADOR'] == aidi])\n",
    "display(df_APORET_detalle[df_APORET_detalle['IDENTIFICADOR'] == aidi])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153fa16",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dashboard_Mayo = pd.read_csv(\"Input/Dashboard_Mayo.csv\", sep=',', engine='python')\n",
    "\n",
    "def format_rut_column(df, col='rut'):\n",
    "    df[col] = df[col].astype(str).str.replace(r'(\\d+)(\\d{1})$', r'\\1-\\2', regex=True)\n",
    "    return df\n",
    "Dashboard_Mayo = format_rut_column(Dashboard_Mayo, col='rut')\n",
    "\n",
    "## Formatear \n",
    "Dashboard_Mayo['Cargos'] = np.where(Dashboard_Mayo['transactionType'] == 'withdrawal', Dashboard_Mayo['amountCLP'], 0)\n",
    "Dashboard_Mayo['Abonos'] = np.where(Dashboard_Mayo['transactionType'] == 'deposit', Dashboard_Mayo['amountCLP'], 0)\n",
    "\n",
    "del Dashboard_Mayo['amountCLP']\n",
    "del Dashboard_Mayo['id']\n",
    "del Dashboard_Mayo['transactionType']\n",
    "\n",
    "Dashboard_Mayo = Dashboard_Mayo.rename(columns={\n",
    "    'rut': 'IDENTIFICADOR',\n",
    "    'createdAtLocal': 'Fecha'})\n",
    "\n",
    "\n",
    "Dashboard_Mayo['Fecha_normalizada'] = pd.to_datetime(Dashboard_Mayo['Fecha'], errors='coerce')\n",
    "Dashboard_Mayo['Fecha_normalizada'] = Dashboard_Mayo['Fecha_normalizada'].dt.strftime('%d-%m-%Y %H:%M')\n",
    "Dashboard_Mayo['Cargos'] = pd.to_numeric(Dashboard_Mayo['Cargos'], errors='coerce')\n",
    "Dashboard_Mayo['Abonos'] = pd.to_numeric(Dashboard_Mayo['Abonos'], errors='coerce')\n",
    "\n",
    "def formatear_identificador(df, col='IDENTIFICADOR'):\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(r'[^0-9kK]', '', regex=True)  # Elimina caracteres no válidos\n",
    "        .str.upper()  # Convierte la K a mayúscula\n",
    "        .str.replace(r'(\\d+)([0-9K])$', r'\\1-\\2', regex=True)  # Agrega el guion antes del último dígito/letra\n",
    "    )\n",
    "    return df\n",
    "\n",
    "Dashboard_Mayo = formatear_identificador(Dashboard_Mayo, col='IDENTIFICADOR')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdddc6e",
   "metadata": {},
   "source": [
    "### BiceWebhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"BiceWebhook = pd.read_excel(\"bice.xlsx\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8c90b",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cartola_clp1 = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-29316-8/30-04.xlsx\", tipo_mon='clp')\n",
    "cartola_clp_RACIONAL = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-35659-3/30-04.xlsx\", tipo_mon='clp') \n",
    "cartola_clp_BETTERPLAN = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-36253-4/30-04.xlsx\", tipo_mon='clp') \n",
    "cartola_clp_ZESTY = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-37487-7/30-04.xlsx\", tipo_mon='clp') \n",
    "cartola_clp5 = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-38571-2/30-04.xlsx\", tipo_mon='clp') ## SHINKANSEN\n",
    "cartola_clp6 = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 01-40540-3/07-03 AL 07-04.xlsx\", tipo_mon='clp')\n",
    "cartola_eur = cargar_cartola_bice(\"Y:\\PROYECTO CONCILIACION\\EJEMPLOS POWER QUARY\\BICE\\BICE 14-20-101366-7 EURO/02-01 AL 02-04.xlsx\", tipo_mon='eur', df_euro_obs=df_euro_obs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_universal = {  \n",
    "#     'query_APORET': f\"\"\"  \n",
    "#         SELECT  \n",
    "#             CARGO_ABONO,  \n",
    "#             NUM_CUENTA,  \n",
    "#             IDENTIFICADOR,  \n",
    "#             NOMBRE_CLI,  \n",
    "#             COD_MOV,  \n",
    "#             DSC_MOV_CAJA,  \n",
    "#             FECHA_MOVIMIENTO,  \n",
    "#             FECHA_LIQUIDACION,  \n",
    "#             MONTO,  \n",
    "#             NOMBRE_ASESOR,  \n",
    "#             TIPO_CAJA,  \n",
    "#             MOV_AUTOMATICO,  \n",
    "#             OBS_MOV_CAJA  \n",
    "#         FROM [Capitaria].[dbo].[MOV_CAJA_CLI_JGG]  \n",
    "#         WHERE IDENTIFICADOR = '17665491-0'  and\n",
    "#         FECHA_MOVIMIENTO BETWEEN CONVERT(datetime, '{F_i}', 120) AND CONVERT(datetime, '{F}', 120)\n",
    "#     \"\"\"  \n",
    "# }\n",
    "\n",
    "# conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# df_APORET_validacion = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "# conn.close()\n",
    "\n",
    "# df_APORET_validacion.sort_values(by='FECHA_MOVIMIENTO', ascending=False).to_excel(\"Temporal/Cliente_validacion1.xlsx\", index=False)\n",
    "# df_APORET_validacion\n",
    "# #and DSC_MOV_CAJA = 'APORTE PATRIMONIAL RC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## webhook aparece la fecha del depósito y la fecha donde va a aparecer en cartola\n",
    "\n",
    "validar = '17665491-0'\n",
    "\n",
    "print(\"------BICE\")\n",
    "display(cartola_clp_RACIONAL[cartola_clp_RACIONAL['IDENTIFICADOR'] == validar])\n",
    "display(BiceWebhook[BiceWebhook['IDENTIFICADOR'] == validar])\n",
    "\n",
    "print(\"------Dashboard\")\n",
    "display(Dashboard_Mayo[Dashboard_Mayo['IDENTIFICADOR'] == validar])\n",
    "print(\"------GPI\")\n",
    "display(df_APORET_detalle[df_APORET_detalle['IDENTIFICADOR'] == validar])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce97fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import pandas as pd\n",
    "\n",
    "# Asegura que las fechas sean del tipo correcto\n",
    "cartola_clp_RACIONAL['Fecha'] = pd.to_datetime(cartola_clp_RACIONAL['Fecha'], format='%d-%m-%Y')\n",
    "df_APORET_detalle['FECHA_MOVIMIENTO'] = pd.to_datetime(df_APORET_detalle['FECHA_MOVIMIENTO'])\n",
    "\n",
    "# Merge por IDENTIFICADOR y monto (Abonos <-> MONTO)\n",
    "df_merge = pd.merge(\n",
    "    cartola_clp_RACIONAL,\n",
    "    df_APORET_detalle,\n",
    "    left_on=['IDENTIFICADOR', 'Abonos'],\n",
    "    right_on=['IDENTIFICADOR', 'MONTO'],\n",
    "    suffixes=('_CARTOLA', '_APORET'),\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calcula la diferencia de días\n",
    "df_merge['DIF_DIAS'] = (df_merge['FECHA_MOVIMIENTO'] - df_merge['Fecha']).dt.days\n",
    "\n",
    "# Filtra matches: FECHA_MOVIMIENTO es igual o hasta 5 días mayor que Fecha\n",
    "df_match = df_merge[(df_merge['DIF_DIAS'] >= 0) & (df_merge['DIF_DIAS'] <= 5)].copy()\n",
    "\n",
    "# Para obtener los no match de cartola_clp_RACIONAL:\n",
    "matched_cartola_idx = df_match['Fecha'].astype(str) + df_match['IDENTIFICADOR'].astype(str) + df_match['Abonos'].astype(str)\n",
    "cartola_idx = cartola_clp_RACIONAL['Fecha'].astype(str) + cartola_clp_RACIONAL['IDENTIFICADOR'].astype(str) + cartola_clp_RACIONAL['Abonos'].astype(str)\n",
    "no_match_cartola = cartola_clp_RACIONAL[~cartola_idx.isin(matched_cartola_idx)]\n",
    "\n",
    "# Para obtener los no match de df_APORET_detalle:\n",
    "matched_aporet_idx = df_match['FECHA_MOVIMIENTO'].astype(str) + df_match['IDENTIFICADOR'].astype(str) + df_match['MONTO'].astype(str)\n",
    "aporet_idx = df_APORET_detalle['FECHA_MOVIMIENTO'].astype(str) + df_APORET_detalle['IDENTIFICADOR'].astype(str) + df_APORET_detalle['MONTO'].astype(str)\n",
    "no_match_aporet = df_APORET_detalle[~aporet_idx.isin(matched_aporet_idx)]\n",
    "\n",
    "# Exporta a Excel con varias pestañas\n",
    "with pd.ExcelWriter('Temporal/output_cartola_match_5dias.xlsx') as writer:\n",
    "    df_match.to_excel(writer, sheet_name='Match', index=False)\n",
    "    no_match_cartola.to_excel(writer, sheet_name='No_Match_CARTOLA', index=False)\n",
    "    no_match_aporet.to_excel(writer, sheet_name='No_Match_APORET', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_universal = {\n",
    "\n",
    "#         'query_APORET': f\"\"\"\n",
    "#         SELECT \n",
    "#                CARGO_ABONO, \n",
    "#                NUM_CUENTA, \n",
    "#                IDENTIFICADOR,\n",
    "\n",
    "               \n",
    "#                NOMBRE_CLI, \n",
    "#                COD_MOV, \n",
    "#                DSC_MOV_CAJA, \n",
    "#                FECHA_MOVIMIENTO,\n",
    "#                FECHA_LIQUIDACION, \n",
    "#                MONTO, \n",
    "#                NOMBRE_ASESOR, \n",
    "#                TIPO_CAJA,\n",
    "#                MOV_AUTOMATICO,\n",
    "#                OBS_MOV_CAJA\n",
    "\n",
    "#         FROM [Capitaria].[dbo].[Movimiento_caja_liquidado]\n",
    "#         where IDENTIFICADOR = '{validar}'\n",
    "         \n",
    "#         \"\"\"\n",
    "# }\n",
    "\n",
    "# conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# df_APORET_validacion = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "# conn.close()\n",
    "\n",
    "# df_APORET_validacion.to_excel(\"validar.xlsx\")\n",
    "\n",
    "# #df_APORET_validacion[df_APORET_validacion['COD_MOV'] == 'APO_PAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cf8e2",
   "metadata": {},
   "source": [
    "### Match Cartola Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58eb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Ordena ambos DataFrames\n",
    "df_to_rut = df_to_rut.sort_values(['IDENTIFICADOR', 'Fecha_transferencia', 'Abonos', 'Cargos'])\n",
    "Dashboard_Mayo = Dashboard_Mayo.sort_values(['IDENTIFICADOR', 'Fecha_normalizada', 'Abonos', 'Cargos'])\n",
    "\n",
    "\n",
    "        def fifo_match_cartola_dashboard(df_to_rut, Dashboard_Mayo):\n",
    "    df_dash = Dashboard_Mayo.copy()\n",
    "    df_dash['usado'] = False\n",
    "    merged_rows = []\n",
    "    for idx, row in df_to_rut.iterrows():\n",
    "        mask = (\n",
    "            (df_dash['IDENTIFICADOR'] == row['IDENTIFICADOR']) &\n",
    "            (df_dash['Abonos'] == row['Abonos']) &\n",
    "            (df_dash['Cargos'] == row['Cargos']) &\n",
    "            (df_dash['Fecha_normalizada'] == row['Fecha_transferencia']) &\n",
    "            (~df_dash['usado'])\n",
    "        )\n",
    "        match = df_dash[mask]\n",
    "        if not match.empty:\n",
    "            first_match_idx = match.index[0]\n",
    "            dash_row = df_dash.loc[first_match_idx].copy()\n",
    "            dash_row = dash_row.add_suffix('_DASH')\n",
    "            merged_row = {**row, **dash_row.to_dict()}\n",
    "            merged_rows.append(merged_row)\n",
    "            df_dash.at[first_match_idx, 'usado'] = True\n",
    "        else:\n",
    "            dash_cols = [col for col in df_dash.columns]\n",
    "            merged_row = {**row}\n",
    "            for col in dash_cols:\n",
    "                merged_row[col + '_DASH'] = None\n",
    "            merged_rows.append(merged_row)\n",
    "    # Agrega los que quedaron sin usar en Dashboard_Mayo\n",
    "    no_match_dash = df_dash[~df_dash['usado']]\n",
    "    for idx, row in no_match_dash.iterrows():\n",
    "        empty_cols = {col: None for col in df_to_rut.columns}\n",
    "        dash_row = row.add_suffix('_DASH').to_dict()\n",
    "        merged_row = {**empty_cols, **dash_row}\n",
    "        merged_rows.append(merged_row)\n",
    "    return pd.DataFrame(merged_rows)\n",
    "\n",
    "df_result = fifo_match_cartola_dashboard(df_to_rut, Dashboard_Mayo)\n",
    "\n",
    "no_match_cartola = df_result[df_result['Abonos_DASH'].isna()]\n",
    "no_match_dashboard = df_result[df_result['Abonos'].isna()]\n",
    "no_match_total = pd.concat([no_match_cartola, no_match_dashboard]).drop_duplicates()\n",
    "\n",
    "with pd.ExcelWriter(\"Output/Dashboard_Cartola_MERGE2.xlsx\") as writer:\n",
    "    df_to_rut.to_excel(writer, sheet_name=\"Rut desde cartola\", index=False)\n",
    "    Dashboard_Mayo.to_excel(writer, sheet_name=\"Dashboard\", index=False)\n",
    "    df_result.to_excel(writer, sheet_name=\"Conciliado\", index=False)\n",
    "    no_match_cartola.to_excel(writer, sheet_name=\"No_match_cartola\", index=False)\n",
    "    no_match_dashboard.to_excel(writer, sheet_name=\"No_match_dashboard\", index=False)\n",
    "    no_match_total.to_excel(writer, sheet_name=\"No_match_total\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9b20b",
   "metadata": {},
   "source": [
    "#### Conciliar BD con Cartolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df_APORET_detalle['IDENTIFICADOR'] = df_APORET_detalle['IDENTIFICADOR'].str.replace('k', 'K', regex=False)\n",
    "df_to_rut['IDENTIFICADOR'] = df_to_rut['IDENTIFICADOR'].str.replace('.', '', regex=False)\n",
    "\n",
    "\n",
    "# ORDENAR AMBOS DF PARA APLICAR FIFO\n",
    "df_to_rut['Fecha'] = pd.to_datetime(df_to_rut['Fecha'], format='%d-%m-%Y', errors='coerce')\n",
    "df_APORET_detalle['FECHA_MOVIMIENTO'] = pd.to_datetime(df_APORET_detalle['FECHA_MOVIMIENTO'], errors='coerce')\n",
    "df_to_rut = df_to_rut.sort_values(['IDENTIFICADOR', 'Abonos', 'Fecha'])\n",
    "df_APORET_detalle = df_APORET_detalle.sort_values(['IDENTIFICADOR', 'MONTO', 'FECHA_MOVIMIENTO'])\n",
    "\n",
    "# Parapara cada fila de df_to_rut, busca el primer match disponible en df_APORET_detalle\n",
    "def fifo_merge(df_cartola, df_aporet):\n",
    "    df_cartola = df_cartola.copy()\n",
    "    df_aporet = df_aporet.copy()\n",
    "    df_aporet['usado'] = False\n",
    "    merged_rows = []\n",
    "    for idx, row in df_cartola.iterrows():\n",
    "        mask = (\n",
    "            (df_aporet['IDENTIFICADOR'] == row['IDENTIFICADOR']) &\n",
    "            (df_aporet['MONTO'] == row['Abonos']) &\n",
    "            (~df_aporet['usado'])\n",
    "        )\n",
    "        match = df_aporet[mask]\n",
    "        if not match.empty:\n",
    "            first_match_idx = match.index[0]\n",
    "            merged_row = {**row, **df_aporet.loc[first_match_idx]}\n",
    "            merged_rows.append(merged_row)\n",
    "            df_aporet.at[first_match_idx, 'usado'] = True\n",
    "        else:\n",
    "            merged_rows.append({**row, **{col: None for col in df_aporet.columns}})\n",
    "    return pd.DataFrame(merged_rows)\n",
    "\n",
    "df_Conciliado = fifo_merge(df_to_rut, df_APORET_detalle)\n",
    "\n",
    "no_match = df_Conciliado[df_Conciliado['MONTO'].isna()]\n",
    "with pd.ExcelWriter(\"Output/Conciliacion_Week2.xlsx\") as writer:\n",
    "    df_to_rut.to_excel(writer, sheet_name=\"Rut desde cartola\", index=False)\n",
    "    df_APORET_detalle.to_excel(writer, sheet_name=\"APORET_detalle\", index=False)\n",
    "    df_Conciliado.to_excel(writer, sheet_name=\"Conciliado_todos\", index=False)\n",
    "    no_match.to_excel(writer, sheet_name=\"No_match\", index=False)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75444a11",
   "metadata": {},
   "source": [
    "### Validación de la conciliación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F_i = '2025-05-01'\n",
    "# F = '2025-05-30'\n",
    "\n",
    "# query_universal = {  \n",
    "#     'query_APORET': f\"\"\"  \n",
    "#         SELECT  \n",
    "#             CARGO_ABONO,  \n",
    "#             NUM_CUENTA,  \n",
    "#             IDENTIFICADOR,  \n",
    "#             NOMBRE_CLI,  \n",
    "#             COD_MOV,  \n",
    "#             DSC_MOV_CAJA,  \n",
    "#             FECHA_MOVIMIENTO,  \n",
    "#             FECHA_LIQUIDACION,  \n",
    "#             MONTO,  \n",
    "#             NOMBRE_ASESOR,  \n",
    "#             TIPO_CAJA,  \n",
    "#             MOV_AUTOMATICO,  \n",
    "#             OBS_MOV_CAJA  \n",
    "#         FROM [Capitaria].[dbo].[MOV_CAJA_CLI_JGG]  \n",
    "#         WHERE IDENTIFICADOR = '18117065-4'  and\n",
    "#         FECHA_MOVIMIENTO BETWEEN CONVERT(datetime, '{F_i}', 120) AND CONVERT(datetime, '{F}', 120)\n",
    "#     \"\"\"  \n",
    "# }\n",
    "\n",
    "# conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# df_APORET_validacion = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "# conn.close()\n",
    "\n",
    "# df_APORET_validacion.sort_values(by='FECHA_MOVIMIENTO', ascending=False).to_excel(\"Temporal/Cliente_validacion1.xlsx\", index=False)\n",
    "\n",
    "# #and DSC_MOV_CAJA = 'APORTE PATRIMONIAL RC'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8bf505",
   "metadata": {},
   "source": [
    "Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_universal = {\n",
    "\n",
    "#         'query_APORET': f\"\"\"\n",
    "#         SELECT \n",
    "#                CARGO_ABONO, \n",
    "#                NUM_CUENTA, \n",
    "#                IDENTIFICADOR,\n",
    "#                NOMBRE_CLI, \n",
    "#                COD_MOV, \n",
    "#                DSC_MOV_CAJA, \n",
    "#                FECHA_MOVIMIENTO,\n",
    "#                FECHA_LIQUIDACION, \n",
    "#                MONTO, \n",
    "#                NOMBRE_ASESOR, \n",
    "#                TIPO_CAJA,\n",
    "#                MOV_AUTOMATICO,\n",
    "#                OBS_MOV_CAJA\n",
    "\n",
    "#         FROM [Capitaria].[dbo].[Movimiento_caja_liquidado]\n",
    "#         where IDENTIFICADOR = '20341629-6'\n",
    "#         \"\"\"\n",
    "# }\n",
    "\n",
    "# conn = pyodbc.connect('DRIVER={SQL Server};SERVER=tcp:mi-sql-prd-002.5bf1e89c8cf2.database.windows.net;DATABASE=capitaria;UID=pablobustamante;PWD=S3cur3!PassPB5sta#2024')\n",
    "# df_APORET_validacion = pd.read_sql(query_universal['query_APORET'], conn)\n",
    "# conn.close()\n",
    "\n",
    "# df_APORET_validacion.sort_values(by='FECHA_MOVIMIENTO', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c3dc7",
   "metadata": {},
   "source": [
    "### Carta Gantt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "df = [dict(Task=\"Estandarizar Cartolas Bancarias\", Start='2025-06-02', Finish='2025-06-08', Resource='Completo'),\n",
    "      dict(Task=\"Aplicar conciliación BBDD, Cartolas, Dashboard\", Start='2025-06-04', Finish='2025-06-22', Resource='Incompleto'),\n",
    "      dict(Task=\"Conciliación Ejecutivos\", Start='2025-06-16', Finish='2025-06-22', Resource='Sin partir'),\n",
    "      dict(Task=\"Visualización mediante correo/reporte\", Start='2025-06-23', Finish='2025-06-29', Resource='Sin partir')]\n",
    "\n",
    "colors = {\n",
    "    'Sin partir': 'rgb(220, 0, 0)',\n",
    "    'Incompleto': (1, 0.9, 0.16),\n",
    "    'Completo': 'rgb(0, 255, 100)'\n",
    "}\n",
    "\n",
    "fig = ff.create_gantt(df, colors=colors, index_col='Resource', show_colorbar=True, group_tasks=True)\n",
    "\n",
    "# Aumentar tamaño de fuente\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        size=16  # Cambia este número para ajustar el tamaño\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a84046",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'Estandarizar Cartolas Bancarias': 'rgb(0, 102, 204)',\n",
    "    'Cruce BBDD y Cartolas': 'rgb(0, 102, 204)',\n",
    "    'Conciliación de cartolas bancarias con GPI y Dashboard de Racional': 'rgb(0, 102, 204)',\n",
    "    'Integrar todas las plataformas en la conciliación de cartolas bancarias BICE': 'rgb(102, 204, 255)',\n",
    "    'Comienzo de estandarización y conciliación con banco Security con Plataforma Racional': 'rgb(0, 204, 150)',\n",
    "    'Conciliación con todas las plataformas en banco Security': 'rgb(204, 204, 0)',\n",
    "    'Entrega de reportes. Integración de código Python con visualización en Power BI': 'rgb(255, 153, 51)',\n",
    "    'Integración con Power BI. Entrega de reportes. Toma de decisiones en base a resultados': 'rgb(255, 102, 102)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f6dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "df = [\n",
    "    dict(Task=\"Semana 02 – 06 Junio\", Start='2025-06-02', Finish='2025-06-08', Resource='Estandarizar Cartolas Bancarias'),\n",
    "    dict(Task=\"Semana 09 – 13 Junio\", Start='2025-06-09', Finish='2025-06-15', Resource='Cruce BBDD y Cartolas'),\n",
    "    dict(Task=\"Semana 16 – 20 Junio\", Start='2025-06-16', Finish='2025-06-22', Resource='Conciliación de cartolas bancarias con GPI y Dashboard de Racional'),\n",
    "    dict(Task=\"Semana 23 – 26 Junio\", Start='2025-06-23', Finish='2025-06-29', Resource='Incorporación del resto de las Fintech al proceso de conciliación'),\n",
    "    dict(Task=\"Semana 30 – 04 Julio\", Start='2025-06-30', Finish='2025-07-06', Resource='Continuación del proceso de incorporación de FinTech'),\n",
    "    dict(Task=\"Semana 07 – 11 Julio\", Start='2025-07-07', Finish='2025-07-13', Resource='Análisis de casos críticos detectados en los resultados de las conciliaciones'),\n",
    "    dict(Task=\"Semana 14 – 18 Julio\", Start='2025-07-14', Finish='2025-07-20', Resource='Entrega de reportes. Integración de código Python con visualización en Power BI'),\n",
    "    dict(Task=\"Semana 21 – 25 Julio\", Start='2025-07-21', Finish='2025-07-27', Resource='Integración con Power BI. Entrega de reportes. Toma de decisiones en base a resultados')\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    'rgb(0, 102, 204)', 'rgb(0, 153, 255)', 'rgb(0, 204, 204)', 'rgb(102, 204, 102)',\n",
    "    'rgb(255, 204, 0)', 'rgb(255, 153, 51)', 'rgb(255, 102, 102)', 'rgb(204, 0, 102)'\n",
    "]\n",
    "\n",
    "resources = [item['Resource'] for item in df]\n",
    "color_map = dict(zip(resources, colors))\n",
    "\n",
    "fig = ff.create_gantt(df, colors=color_map, index_col='Resource', show_colorbar=True, group_tasks=True)\n",
    "\n",
    "# Reordenar manualmente los traces para que la leyenda siga el orden de 'resources'\n",
    "ordered_traces = []\n",
    "for resource in resources:\n",
    "    for trace in fig.data:\n",
    "        if trace.name == resource:\n",
    "            ordered_traces.append(trace)\n",
    "fig.data = tuple(ordered_traces)\n",
    "\n",
    "fig.update_layout(\n",
    "    width=2000,  # Aumenta el ancho\n",
    "    height=700,  # Aumenta el alto\n",
    "    font=dict(size=17),\n",
    "    legend=dict(\n",
    "        font=dict(size=18),  # Achica la leyenda\n",
    "        title_font=dict(size=16),\n",
    "        traceorder=\"normal\",\n",
    "        itemsizing='constant'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
